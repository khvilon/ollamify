services:

  zeus:
    build:
      context: .
      dockerfile: services/zeus/Dockerfile
    volumes:
      - ./.env:/app/.env
      - ./services/zeus/src:/app/src
    depends_on:
      db:
        condition: service_healthy
      vector-db:
        condition: service_started
      ollama:
        condition: service_healthy
      reranker:
        condition: service_started
      frida:
        condition: service_started
      tts:
        condition: service_started
      stt:
        condition: service_started
    environment:
      - ZEUS_PORT=80
      - POSTGRES_PORT=${POSTGRES_PORT}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_HOST=db
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - OPENROUTER_URL=${OPENROUTER_URL}
      - QDRANT_HOST=vector-db
      - QDRANT_PORT=6333
    expose:
      - "80"
    container_name: zeus
    networks:
      - app-network

  ollama:
    environment:
      # Bind primary Ollama instance to GPU 0
      - NVIDIA_VISIBLE_DEVICES=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]
              capabilities: [gpu]

  frida:
    environment:
      - TRANSFORMERS_CACHE=/app/models
      - NVIDIA_VISIBLE_DEVICES=all
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  reranker:
    build:
      context: ./services/reranker
      dockerfile: Dockerfile.gpu
    environment:
      - RERANKER_MODEL=${RERANKER_MODEL}
      - PORT=8001
      - TRANSFORMERS_CACHE=/app/models
      - HF_HUB_ENABLE_HF_TRANSFER=0
      - NVIDIA_VISIBLE_DEVICES=all
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  tts:
    build:
      context: ./services/tts
      dockerfile: Dockerfile
    volumes:
      - tts_models:/app/models
    ports:
      - "8003:8003"
    expose:
      - "8003"
    environment:
      - PORT=8003
      - TORCH_HOME=/app/models
      - HF_HOME=/app/models
      - TRANSFORMERS_CACHE=/app/models
      - NVIDIA_VISIBLE_DEVICES=all
    container_name: tts
    networks:
      - app-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  stt:
    build:
      context: ./services/stt
      dockerfile: Dockerfile.gpu
    volumes:
      - stt_models:/app/models
    ports:
      - "8004:8004"
    expose:
      - "8004"
    environment:
      - PORT=8004
      - WHISPER_CACHE=/app/models
      - TORCH_HOME=/app/models
      - HF_HOME=/app/models
      - NVIDIA_VISIBLE_DEVICES=all
    container_name: stt
    networks:
      - app-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8004/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

  gpu-info:
    build:
      context: .
      dockerfile: services/gpu-info/Dockerfile
    environment:
      - PORT=8005
      - NVIDIA_VISIBLE_DEVICES=all
    expose:
      - "8005"
    container_name: gpu-info
    networks:
      - app-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8005/health').read()"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

volumes:
  tts_models:
    name: ollamify-tts-models
  stt_models:
    name: ollamify-stt-models 