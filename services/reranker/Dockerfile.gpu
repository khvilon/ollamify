FROM pytorch/pytorch:2.5.0-cuda12.4-cudnn9-runtime

WORKDIR /app

# Устанавливаем необходимые зависимости
RUN apt-get update && apt-get install -y \
    build-essential \
    git \
    curl \
    ca-certificates \
    && rm -rf /var/lib/apt/lists/*

# Копируем и устанавливаем зависимости Python
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Обновляем PyTorch до стабильной версии 2.7.1 с CUDA 12.8 для поддержки RTX 5070 Ti
RUN pip install --no-cache-dir --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# Устанавливаем дополнительные зависимости, которые могут потребоваться для разных моделей
RUN pip install --no-cache-dir \
    "transformers[sentencepiece,onnx]>=4.36.0" \
    "huggingface-hub>=0.19.0" \
    accelerate>=0.25.0 \
    einops>=0.7.0 \
    tiktoken>=0.5.0 \
    safetensors>=0.4.0 \
    bitsandbytes>=0.41.0

# Создаем директорию для кеша моделей и устанавливаем права
RUN mkdir -p /app/models && chmod 777 /app/models
ENV TRANSFORMERS_CACHE=/app/models
# Разрешаем всем пользователям писать в папку site-packages (проверяем существование)
RUN find /opt/conda -name "site-packages" -type d -exec chmod -R 777 {} \; 2>/dev/null || \
    find /usr/local -name "site-packages" -type d -exec chmod -R 777 {} \; 2>/dev/null || true

# Устанавливаем переменные окружения для GPU
ENV NVIDIA_VISIBLE_DEVICES=all
ENV CUDA_VISIBLE_DEVICES=0
ENV PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128,expandable_segments:True
ENV CUDA_LAUNCH_BLOCKING=1
ENV TORCH_CUDA_ARCH_LIST="7.0;7.5;8.0;8.6;8.9;9.0;12.0"
ENV TORCH_USE_CUDA_DSA=1
ENV PYTORCH_NVFUSER_DISABLE=1
ENV TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1

# Копируем код приложения
COPY app.py .

# Запускаем приложение
CMD ["python", "-m", "uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8001"] 